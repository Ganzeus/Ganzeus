韩国“N 号房”事件因Deep Fake再现，探究背后的技术和应对方法

## 1. 背景
据《环球时报》援引韩媒报道，针对女性的深度伪造犯罪在韩国日趋猖獗，不仅大学校园中出现此类案件，甚至连中小学、军队等场所也成为高发地。社交媒体上，特别是Telegram群组中不断有受害学校及被害者信息流出。

韩国男性频频使用DeepFake技术，将熟人女性的照片换脸到现有的色情视频中，并在Telegram上进行传播和戏弄。

此前震惊世界的韩国“N号房”事件，正在频繁“更新”2.0乃至3.0版本。

![alt text](<assest/韩国“N 号房”事件因Deep Fake再现，探究背后的技术和应对方法/01.png>)

## 2. 什么是DeepFake？
Deepfake是一种基于深度学习技术的人工智能应用，它可以创建极其逼真的篡改图像或视频。这项技术通过使用生成对抗网络（GANs）, 扩散模型（Diffusion Models）等算法，能够将一个人的面部特征或其他特征与另一个人的图像或视频融合，生成看起来非常真实的虚假内容。

Deepfake一词最早由一位Reddit用户在2017年创造，最初用于制作名人的假色情视频，但随着技术的发展，其应用范围已经扩大到更多领域，包括娱乐、政治、教育等。

![alt text](<assest/韩国“N 号房”事件因Deep Fake再现，探究背后的技术和应对方法/00.png>)

技术本身是中立的，但是错误的使用会导致不良的后果，为了应对DeepFake带来的危害，首先我们得了解其背后的技术原理。DeepFake可以有很多种实现方式，其中Diffusion Model是一种比较流行的技术。

## 3. Diffusion Model

Diffussion Model是最近流行的AIGC模型之一，它是一种生成模型，可以用来生成高质量的图像和视频。其核心思想是通过对图像或视频的像素进行扰动，逐渐减小扰动的强度，从而生成逼真的图像或视频。

想象一下，你有一张清晰的家庭照片，你想通过一系列奇怪的步骤来“隐藏”这张照片的信息，然后再找回来。这个“隐藏”和“找回”的过程就是diffusion models的核心。

`正向扩散（Forward Diffusion）`：

首先，你开始在照片上随意涂鸦，这就像是在原始数据上添加噪声。你一遍又一遍地这样做，每次都增加更多的涂鸦，直到照片变得无法辨认，只剩下一团混乱的颜色和线条。

这个过程就像是在数据中逐渐加入噪声，直到它变成完全随机的噪声。

`逆向扩散（Reverse Diffusion）`：

现在，你有一张完全被涂鸦覆盖的照片，你的任务是恢复出原始的家庭照片。你开始逐渐擦掉涂鸦，每次擦掉一点，直到所有的涂鸦都消失，家庭照片再次变得清晰可见。这个过程就像是从噪声中逐步恢复出原始数据。
在diffusion models中，这个过程是通过数学和计算模型来实现的。

模型首先学习如何生成涂鸦（正向过程），然后学习如何擦掉涂鸦（逆向过程）。这个逆向过程是通过训练一个神经网络来完成的，这个网络被训练来预测在每一步需要去除多少噪声，以便最终生成与原始数据相似的新数据。


## 如何换脸？

在Diffusion Model中，是如何实现生成不存在的照片的呢？

在这个模型中，我们可以对图片添加描述，这个描述通过Embedding的方式，将图片和描述联系起来。这样，我们就可以通过描述生成我们想要的图片。由于模型的强大生成能力，几乎可以以假乱真。

![alt text](<assest/韩国“N 号房”事件因Deep Fake再现，探究背后的技术和应对方法/12.png>)

比如，我们有一张牛油果的照片和有一段文字“一颗牛油果”来训练模型，模型就可以根据“生成一张牛油果照片”的指令生成一张对应的照片：

![alt text](<assest/韩国“N 号房”事件因Deep Fake再现，探究背后的技术和应对方法/13.png>)

同样的，我们有一张办公椅的照片和有一段文字“一把办公椅”，来训练模型，模型就可以根据“生成一张办公椅照片”的指令生成一张对应的照片：

![alt text](<assest/韩国“N 号房”事件因Deep Fake再现，探究背后的技术和应对方法/14.png>)

此时，模型已经学习到了牛油果是什么，椅子是什么，这时你可以给它一个指令：“生成牛油果办公椅”，它就有了创造能力。

![alt text](<assest/韩国“N 号房”事件因Deep Fake再现，探究背后的技术和应对方法/15.png>)

类比到这次韩国的DeepFake事件，别有用心的人会这样做
1. 使用大量色情图片，让模型学习色情特征，此时模型知道了什么是裸体;
2. 获取受害者的正常图片，让模型学习受害者的脸部特征，此时模型知道受害者的长相;
3. 通过描述让模型生成不存在的受害者色情图片，此时模型可以生成以假乱真的、虚假的受害者的裸体照片。


## 4. 如何应对Deepfake？
潘多拉魔盒已经打开，没有人能避免自己的脸部特征被别人使用。

我看到最近有人在GitHub上开源了一个AI模型，用来事后检测图片是否是DeepFake的。

我认为有千日捉贼，无千日防贼，虽然我们没有办法切断生成源，但是我们可以切断传播途径。


## 参考

<div id="refer-anchor-1"></div>

[1] [韩国再现“N号房”事件，大量Deepfake性犯罪引恐慌，超500所学校受影响](https://www.163.com/dy/article/JB96QC3R051180F7.html)

[2] [她决定开源AI模型，正面宣战“N号房2.0”](https://finance.sina.com.cn/cj/2024-09-04/doc-incmxxut6381305.shtml)

[3] [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)

[4] [Denoising Diffusion Implicit Models](https://arxiv.org/abs/2010.02502)

[5] [deeplearning.ai](https://learn.deeplearning.ai/courses/diffusion-models/)

[6] [Diffusion Deepfake](https://arxiv.org/abs/2404.01579)

## 欢迎关注我的GitHub和微信公众号，来不及解释了，快上船！

[GitHub: LLMForEverybody](https://github.com/luhengshiwo/LLMForEverybody)