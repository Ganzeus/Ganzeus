LoRA不是唯一选择，Adapters微调大模型的奥秘（二）LoRA

LoRA（Low-Rank Adapter）[1](#refer-anchor-1) 是最流行的 PEFT 方法之一，如果你刚开始使用 PEFT，它是一个很好的起点。它最初是为大型语言模型开发的，但由于其效率和有效性，它是一种非常流行的扩散模型训练方法。

## 1.技术解读

![alt text](<assest/大模型微调之Adapters（二）LoRA/lora_animated (1).gif>)

在大型语言模型中，权重矩阵通常具有较大的维度，这使得在微调时需要处理大量的参数。LoRA方法通过将这些大的权重矩阵分解为两个较小的矩阵的乘积（即低秩分解），来近似表示原始的权重矩阵。这样做的好处是，我们只需要更新这两个较小矩阵的参数，而不是原始大矩阵的所有参数，大大减少了微调的计算成本。

LoRA的实施过程大致如下：

1. 选择模型中需要微调的层（如Transformer模型中的自注意力层）；
2. 在这些层的权重矩阵中引入两个新的可训练矩阵A和B，它们的维度远小于原始权重矩阵；
3. 在模型的前向传播过程中，通过计算原始权重矩阵与矩阵A和B乘积的和来得到新的输出，其中矩阵A和B的乘积代表了低秩矩阵的更新；
4. 在训练过程中，只更新A和B的参数，而保持原始权重矩阵不变；

LoRA的优点在于它能够在保持模型性能的同时，显著减少微调所需的计算资源，这对于资源有限的研究和应用场景非常有价值。此外，LoRA还可以与其他参数高效微调技术结合使用，进一步提高微调的效率。

需要注意的是，LoRA方法的秩（即矩阵A和B的维度）是一个重要的超参数，需要根据具体任务进行调整。较低的秩可以进一步减少参数数量，但可能会导致模型无法充分学习到任务特定的信息；而较高的秩则可能需要更多的计算资源，但可以提供更好的微调性能。

## 2.直观理解

想象一下，你已经是一个经验丰富的厨师，这意味着你已经拥有一套完整的烹饪技巧（这就像是一个预训练的语言模型）。现在，如果你想要学习如何制作一种特定的新菜肴，比如寿司，你不需要重新学习所有的烹饪技巧，你只需要学习一些新的特定技能，比如如何正确切割鱼片（这就是微调）。

在LoRA中，我们把这个过程想象成在原有的烹饪技巧（模型的权重）基础上，添加一些新的小工具或技巧。这些新的工具或技巧可以看作是两个小的矩阵（A和B），它们结合起来可以帮助你更好地制作寿司，但它们本身并不包含所有的烹饪技巧，只是针对寿司制作的一些关键点。


## 参考

<div id="refer-anchor-1"></div>

[1] [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685)

## 欢迎关注我的GitHub和微信公众号[真-忒修斯之船]，来不及解释了，快上船！

[GitHub: LLMForEverybody](https://github.com/luhengshiwo/LLMForEverybody)

仓库上有原始的Markdown文件，完全开源，欢迎大家Star和Fork！