{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter   # 用来将网络数据发送到tensorboard中\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "class RunBuilder():\n",
    "    @staticmethod          # 静态函数可以直接用类名调用，不需要创建类的实例\n",
    "    def get_runs(params):\n",
    "        Run = namedtuple(\"Run\", params.keys())   # 用于构建带名字的元组，名字为\"Run\"\n",
    "        \n",
    "        runs = []\n",
    "        for v in product(*params.values()):      # 对于所有超参数的组合\n",
    "            runs.append(Run(*v))                 # 构建一个带名元组\n",
    "        \n",
    "        return runs\n",
    "    \n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_strat_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None       # summarywriter\n",
    "        \n",
    "    def begin_run(self, run, network, loader):        # 每次运行开始调用\n",
    "        self.run_start_time = time.time()\n",
    "        \n",
    "        self.run_params = run      # run代表所有超参数的元组\n",
    "        self.run_count += 1\n",
    "        \n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')    # 为本次运行起名\n",
    "        \n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image('image', grid)\n",
    "        # self.tb.add_graph(self.network, images)\n",
    "        self.tb.add_graph(\n",
    "            self.network,\n",
    "            images.to(getattr(run, 'device', 'cpu'))\n",
    "        )\n",
    "        \n",
    "    def end_run(self):           # 每次运行结束调用\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0     # 初始化epoch计数\n",
    "        \n",
    "    def begin_epoch(self):         # 每个epoch开始时\n",
    "        self.epoch_start_time = time.time()  # 设置开始时间\n",
    "        \n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "        \n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "        \n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "            \n",
    "        results = OrderedDict()            # 有序字典存放运行结果\n",
    "        # 把需要的数据加入字典\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results[\"loss\"] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results[\"epoch duration\"] = epoch_duration\n",
    "        results[\"run duration\"] = run_duration\n",
    "        for k, v in self.run_params._asdict().items(): # 对于本次运行的所有超参数，转换成字典，并提取键值\n",
    "            results[k] = v         # 加入results\n",
    "            \n",
    "        self.run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')  # 利用pandas将结果格式化输出\n",
    "        \n",
    "        clear_output(wait=True)    # 清空Jupyter notebook当前输出\n",
    "        display(df)                # 在Jupyter notebook中输出结果\n",
    "\n",
    "    def track_loss(self, loss):\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "\n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data,\n",
    "            orient='columns'\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)     # Linear = fully connected(fc) = dense\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)                   # 卷积层中不包含激活函数，需要手动添加\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)     # 池化操作（没有权重的函数不能称为层）\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12*4*4)       # 必须手动flatten\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        # t = F.softmax(t, dim=1)           # 不直接在forward中用softmax，而是在训练过程中用cross-entropy损失函数计算loss，其中自带softmax\n",
    "        \n",
    "        return t\n",
    "    \n",
    "    \n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(train_set, batch_size=len(train_set), num_workers=1)    # 一次读入全部图像\n",
    "data = next(iter(loader))\n",
    "data[0].mean(), data[0].std()    # 求所有图像所有像素的均值和标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Way (手算)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(train_set, batch_size=1000, num_workers=1)  # 一批一批的读入\n",
    "num_of_pixels = len(train_set) * 28 * 28    # 所有图像的像素总数\n",
    "\n",
    "total_sum = 0       # 所有图像的像素值之和\n",
    "for batch in loader: total_sum += batch[0].sum()    # 计算像素和\n",
    "\n",
    "# 算均值\n",
    "mean = total_sum / num_of_pixels\n",
    "\n",
    "# 算标准差\n",
    "sum_of_squared_error = 0\n",
    "for batch in loader:\n",
    "    sum_of_squared_error += ((batch[0] - mean).pow(2)).sum()\n",
    "std = torch.sqrt(sum_of_squared_error / num_of_pixels)\n",
    "\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x218c77146d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loader = DataLoader(train_set, batch_size=1000, num_workers=1)    # 一次读入全部图像\n",
    "data = next(iter(loader))\n",
    "plt.hist(data[0].flatten())\n",
    "plt.axvline(data[0].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the mean and std values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_normal = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter   # 用来将网络数据发送到tensorboard中\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "class RunBuilder():\n",
    "    @staticmethod          # 静态函数可以直接用类名调用，不需要创建类的实例\n",
    "    def get_runs(params):\n",
    "        Run = namedtuple(\"Run\", params.keys())   # 用于构建带名字的元组，名字为\"Run\"\n",
    "        \n",
    "        runs = []\n",
    "        for v in product(*params.values()):      # 对于所有超参数的组合\n",
    "            runs.append(Run(*v))                 # 构建一个带名元组\n",
    "        \n",
    "        return runs\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_strat_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None       # summarywriter\n",
    "        \n",
    "    def begin_run(self, run, network, loader):        # 每次运行开始调用\n",
    "        self.run_start_time = time.time()\n",
    "        \n",
    "        self.run_params = run      # run代表所有超参数的元组\n",
    "        self.run_count += 1\n",
    "        \n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')    # 为本次运行起名\n",
    "        \n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image('image', grid)\n",
    "        self.tb.add_graph(self.network, images)\n",
    "        \n",
    "    def end_run(self):           # 每次运行结束调用\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0     # 初始化epoch计数\n",
    "        \n",
    "    def begin_epoch(self):         # 每个epoch开始时\n",
    "        self.epoch_start_time = time.time()  # 设置开始时间\n",
    "        \n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "        \n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "        \n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "            \n",
    "        results = OrderedDict()            # 有序字典存放运行结果\n",
    "        # 把需要的数据加入字典\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results[\"loss\"] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results[\"epoch duration\"] = epoch_duration\n",
    "        results[\"run duration\"] = run_duration\n",
    "        for k, v in self.run_params._asdict().items(): # 对于本次运行的所有超参数，转换成字典，并提取键值\n",
    "            results[k] = v         # 加入results\n",
    "            \n",
    "        self.run_data.append(results)   # 加入run_data列表\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')  # 利用pandas将结果格式化输出\n",
    "        \n",
    "        clear_output(wait=True)    # 清空Jupyter notebook当前输出\n",
    "        display(df)                # 在Jupyter notebook中输出结果\n",
    "\n",
    "    def track_loss(self, loss):\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "\n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data,\n",
    "            orient='columns'\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "network1 = nn.Sequential(           # 没有BatchNorm\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(in_features=12*4*4, out_features=120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=120, out_features=60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=60, out_features=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "network2 = nn.Sequential(           # 有BatchNorm\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.BatchNorm2d(6),  # 6为上一层的输出通道数\n",
    "    nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(in_features=12*4*4, out_features=120),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(120), # 120为上一层的输出\n",
    "    nn.Linear(in_features=120, out_features=60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=60, out_features=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "loader = DataLoader(train_set, batch_size=len(train_set), num_workers=1)    # 一次读入全部图像\n",
    "data = next(iter(loader))\n",
    "mean = data[0].mean()\n",
    "std = data[0].std()    # 求所有图像所有像素的均值和标准差\n",
    "\n",
    "train_set_normal = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsets = {\n",
    "    'not_normal':train_set,\n",
    "    'normal': train_set_normal\n",
    "}\n",
    "networks = {\n",
    "    \"no_batch_norm\": network1,\n",
    "    \"batch_norm\": network2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>device</th>\n",
       "      <th>train_set</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906163</td>\n",
       "      <td>0.656350</td>\n",
       "      <td>16.917409</td>\n",
       "      <td>20.522625</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.478183</td>\n",
       "      <td>0.820067</td>\n",
       "      <td>23.543191</td>\n",
       "      <td>44.183226</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.401715</td>\n",
       "      <td>0.852017</td>\n",
       "      <td>17.679706</td>\n",
       "      <td>61.940129</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.353065</td>\n",
       "      <td>0.870400</td>\n",
       "      <td>17.450009</td>\n",
       "      <td>79.476841</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.324558</td>\n",
       "      <td>0.879450</td>\n",
       "      <td>17.428647</td>\n",
       "      <td>96.989269</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584009</td>\n",
       "      <td>0.787333</td>\n",
       "      <td>20.444985</td>\n",
       "      <td>26.389428</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344745</td>\n",
       "      <td>0.872417</td>\n",
       "      <td>17.025568</td>\n",
       "      <td>43.538210</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.306971</td>\n",
       "      <td>0.885883</td>\n",
       "      <td>19.185883</td>\n",
       "      <td>62.826512</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.281029</td>\n",
       "      <td>0.894917</td>\n",
       "      <td>27.317093</td>\n",
       "      <td>90.360705</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.265725</td>\n",
       "      <td>0.899233</td>\n",
       "      <td>30.102407</td>\n",
       "      <td>120.601357</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418516</td>\n",
       "      <td>0.851883</td>\n",
       "      <td>13.247268</td>\n",
       "      <td>18.383134</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.313022</td>\n",
       "      <td>0.883983</td>\n",
       "      <td>13.848185</td>\n",
       "      <td>32.309505</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.297950</td>\n",
       "      <td>0.889783</td>\n",
       "      <td>14.588526</td>\n",
       "      <td>46.979264</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.280509</td>\n",
       "      <td>0.896833</td>\n",
       "      <td>18.100440</td>\n",
       "      <td>65.181212</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.266972</td>\n",
       "      <td>0.901283</td>\n",
       "      <td>15.554151</td>\n",
       "      <td>80.846552</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336625</td>\n",
       "      <td>0.876250</td>\n",
       "      <td>16.796803</td>\n",
       "      <td>21.274983</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.279871</td>\n",
       "      <td>0.896233</td>\n",
       "      <td>13.741382</td>\n",
       "      <td>35.134885</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.262104</td>\n",
       "      <td>0.901683</td>\n",
       "      <td>19.545286</td>\n",
       "      <td>54.865579</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250828</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>14.798220</td>\n",
       "      <td>69.806093</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.238590</td>\n",
       "      <td>0.910067</td>\n",
       "      <td>18.124465</td>\n",
       "      <td>88.058664</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0     1      1  0.906163  0.656350       16.917409     20.522625  0.01   \n",
       "1     1      2  0.478183  0.820067       23.543191     44.183226  0.01   \n",
       "2     1      3  0.401715  0.852017       17.679706     61.940129  0.01   \n",
       "3     1      4  0.353065  0.870400       17.450009     79.476841  0.01   \n",
       "4     1      5  0.324558  0.879450       17.428647     96.989269  0.01   \n",
       "5     2      1  0.584009  0.787333       20.444985     26.389428  0.01   \n",
       "6     2      2  0.344745  0.872417       17.025568     43.538210  0.01   \n",
       "7     2      3  0.306971  0.885883       19.185883     62.826512  0.01   \n",
       "8     2      4  0.281029  0.894917       27.317093     90.360705  0.01   \n",
       "9     2      5  0.265725  0.899233       30.102407    120.601357  0.01   \n",
       "10    3      1  0.418516  0.851883       13.247268     18.383134  0.01   \n",
       "11    3      2  0.313022  0.883983       13.848185     32.309505  0.01   \n",
       "12    3      3  0.297950  0.889783       14.588526     46.979264  0.01   \n",
       "13    3      4  0.280509  0.896833       18.100440     65.181212  0.01   \n",
       "14    3      5  0.266972  0.901283       15.554151     80.846552  0.01   \n",
       "15    4      1  0.336625  0.876250       16.796803     21.274983  0.01   \n",
       "16    4      2  0.279871  0.896233       13.741382     35.134885  0.01   \n",
       "17    4      3  0.262104  0.901683       19.545286     54.865579  0.01   \n",
       "18    4      4  0.250828  0.906000       14.798220     69.806093  0.01   \n",
       "19    4      5  0.238590  0.910067       18.124465     88.058664  0.01   \n",
       "\n",
       "    batch_size  shuffle  num_workers device   train_set        network  \n",
       "0         1000     True            1    cpu      normal  no_batch_norm  \n",
       "1         1000     True            1    cpu      normal  no_batch_norm  \n",
       "2         1000     True            1    cpu      normal  no_batch_norm  \n",
       "3         1000     True            1    cpu      normal  no_batch_norm  \n",
       "4         1000     True            1    cpu      normal  no_batch_norm  \n",
       "5         1000     True            1    cpu      normal     batch_norm  \n",
       "6         1000     True            1    cpu      normal     batch_norm  \n",
       "7         1000     True            1    cpu      normal     batch_norm  \n",
       "8         1000     True            1    cpu      normal     batch_norm  \n",
       "9         1000     True            1    cpu      normal     batch_norm  \n",
       "10        1000     True            1    cpu  not_normal  no_batch_norm  \n",
       "11        1000     True            1    cpu  not_normal  no_batch_norm  \n",
       "12        1000     True            1    cpu  not_normal  no_batch_norm  \n",
       "13        1000     True            1    cpu  not_normal  no_batch_norm  \n",
       "14        1000     True            1    cpu  not_normal  no_batch_norm  \n",
       "15        1000     True            1    cpu  not_normal     batch_norm  \n",
       "16        1000     True            1    cpu  not_normal     batch_norm  \n",
       "17        1000     True            1    cpu  not_normal     batch_norm  \n",
       "18        1000     True            1    cpu  not_normal     batch_norm  \n",
       "19        1000     True            1    cpu  not_normal     batch_norm  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [0.01],\n",
    "    batch_size = [1000],\n",
    "    shuffle=[True],\n",
    "    num_workers = [1],\n",
    "    device = ['cpu'],\n",
    "    train_set = ['normal', 'not_normal'],\n",
    "    network = list(networks.keys())     # 和上面手写train_set列表效果一样，但可以动态变化                 \n",
    ")\n",
    "\n",
    "m = RunManager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    device = torch.device(run.device)\n",
    "    network = networks[run.network].to(device)\n",
    "    loader = DataLoader(trainsets[run.train_set], batch_size=run.batch_size, shuffle=run.shuffle, num_workers=run.num_workers)\n",
    "    optimizer = optim.Adam(network.parameters(), lr = run.lr)\n",
    "\n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(5):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            images, labels = batch      # get batch\n",
    "            preds = network(images)     # pass batch\n",
    "            loss = F.cross_entropy(preds, labels)   # caculate loss\n",
    "            optimizer.zero_grad()       # zero gradients\n",
    "            loss.backward()             # calculate gradients\n",
    "            optimizer.step()            # update weights\n",
    "\n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>device</th>\n",
       "      <th>train_set</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.238590</td>\n",
       "      <td>0.910067</td>\n",
       "      <td>18.124465</td>\n",
       "      <td>88.058664</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250828</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>14.798220</td>\n",
       "      <td>69.806093</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.262104</td>\n",
       "      <td>0.901683</td>\n",
       "      <td>19.545286</td>\n",
       "      <td>54.865579</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.266972</td>\n",
       "      <td>0.901283</td>\n",
       "      <td>15.554151</td>\n",
       "      <td>80.846552</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.265725</td>\n",
       "      <td>0.899233</td>\n",
       "      <td>30.102407</td>\n",
       "      <td>120.601357</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.280509</td>\n",
       "      <td>0.896833</td>\n",
       "      <td>18.100440</td>\n",
       "      <td>65.181212</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.279871</td>\n",
       "      <td>0.896233</td>\n",
       "      <td>13.741382</td>\n",
       "      <td>35.134885</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.281029</td>\n",
       "      <td>0.894917</td>\n",
       "      <td>27.317093</td>\n",
       "      <td>90.360705</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.297950</td>\n",
       "      <td>0.889783</td>\n",
       "      <td>14.588526</td>\n",
       "      <td>46.979264</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.306971</td>\n",
       "      <td>0.885883</td>\n",
       "      <td>19.185883</td>\n",
       "      <td>62.826512</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.313022</td>\n",
       "      <td>0.883983</td>\n",
       "      <td>13.848185</td>\n",
       "      <td>32.309505</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.324558</td>\n",
       "      <td>0.879450</td>\n",
       "      <td>17.428647</td>\n",
       "      <td>96.989269</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336625</td>\n",
       "      <td>0.876250</td>\n",
       "      <td>16.796803</td>\n",
       "      <td>21.274983</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344745</td>\n",
       "      <td>0.872417</td>\n",
       "      <td>17.025568</td>\n",
       "      <td>43.538210</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.353065</td>\n",
       "      <td>0.870400</td>\n",
       "      <td>17.450009</td>\n",
       "      <td>79.476841</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.401715</td>\n",
       "      <td>0.852017</td>\n",
       "      <td>17.679706</td>\n",
       "      <td>61.940129</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418516</td>\n",
       "      <td>0.851883</td>\n",
       "      <td>13.247268</td>\n",
       "      <td>18.383134</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>not_normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.478183</td>\n",
       "      <td>0.820067</td>\n",
       "      <td>23.543191</td>\n",
       "      <td>44.183226</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584009</td>\n",
       "      <td>0.787333</td>\n",
       "      <td>20.444985</td>\n",
       "      <td>26.389428</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906163</td>\n",
       "      <td>0.656350</td>\n",
       "      <td>16.917409</td>\n",
       "      <td>20.522625</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "19    4      5  0.238590  0.910067       18.124465     88.058664  0.01   \n",
       "18    4      4  0.250828  0.906000       14.798220     69.806093  0.01   \n",
       "17    4      3  0.262104  0.901683       19.545286     54.865579  0.01   \n",
       "14    3      5  0.266972  0.901283       15.554151     80.846552  0.01   \n",
       "9     2      5  0.265725  0.899233       30.102407    120.601357  0.01   \n",
       "13    3      4  0.280509  0.896833       18.100440     65.181212  0.01   \n",
       "16    4      2  0.279871  0.896233       13.741382     35.134885  0.01   \n",
       "8     2      4  0.281029  0.894917       27.317093     90.360705  0.01   \n",
       "12    3      3  0.297950  0.889783       14.588526     46.979264  0.01   \n",
       "7     2      3  0.306971  0.885883       19.185883     62.826512  0.01   \n",
       "11    3      2  0.313022  0.883983       13.848185     32.309505  0.01   \n",
       "4     1      5  0.324558  0.879450       17.428647     96.989269  0.01   \n",
       "15    4      1  0.336625  0.876250       16.796803     21.274983  0.01   \n",
       "6     2      2  0.344745  0.872417       17.025568     43.538210  0.01   \n",
       "3     1      4  0.353065  0.870400       17.450009     79.476841  0.01   \n",
       "2     1      3  0.401715  0.852017       17.679706     61.940129  0.01   \n",
       "10    3      1  0.418516  0.851883       13.247268     18.383134  0.01   \n",
       "1     1      2  0.478183  0.820067       23.543191     44.183226  0.01   \n",
       "5     2      1  0.584009  0.787333       20.444985     26.389428  0.01   \n",
       "0     1      1  0.906163  0.656350       16.917409     20.522625  0.01   \n",
       "\n",
       "    batch_size  shuffle  num_workers device   train_set        network  \n",
       "19        1000     True            1    cpu  not_normal     batch_norm  \n",
       "18        1000     True            1    cpu  not_normal     batch_norm  \n",
       "17        1000     True            1    cpu  not_normal     batch_norm  \n",
       "14        1000     True            1    cpu  not_normal  no_batch_norm  \n",
       "9         1000     True            1    cpu      normal     batch_norm  \n",
       "13        1000     True            1    cpu  not_normal  no_batch_norm  \n",
       "16        1000     True            1    cpu  not_normal     batch_norm  \n",
       "8         1000     True            1    cpu      normal     batch_norm  \n",
       "12        1000     True            1    cpu  not_normal  no_batch_norm  \n",
       "7         1000     True            1    cpu      normal     batch_norm  \n",
       "11        1000     True            1    cpu  not_normal  no_batch_norm  \n",
       "4         1000     True            1    cpu      normal  no_batch_norm  \n",
       "15        1000     True            1    cpu  not_normal     batch_norm  \n",
       "6         1000     True            1    cpu      normal     batch_norm  \n",
       "3         1000     True            1    cpu      normal  no_batch_norm  \n",
       "2         1000     True            1    cpu      normal  no_batch_norm  \n",
       "10        1000     True            1    cpu  not_normal  no_batch_norm  \n",
       "1         1000     True            1    cpu      normal  no_batch_norm  \n",
       "5         1000     True            1    cpu      normal     batch_norm  \n",
       "0         1000     True            1    cpu      normal  no_batch_norm  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(m.run_data).sort_values('accuracy', ascending=False) # 将输出按准确率降序排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
