{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a0abf7",
   "metadata": {},
   "source": [
    "# Using TensorBoard with PyTorch - Deep Learning Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d67529b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T05:21:31.741202Z",
     "start_time": "2024-02-20T05:21:24.456609Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] 找不到指定的程序。\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter   # 用来将网络数据发送到tensorboard中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9292cd27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T07:58:09.865760Z",
     "start_time": "2023-10-13T07:58:09.840494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "0.14.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc720d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T07:59:10.155884Z",
     "start_time": "2023-10-13T07:59:10.063016Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):       # 预测正确的数量\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)     # Linear = fully connected(fc) = dense\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)                   # 卷积层中不包含激活函数，需要手动添加\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)     # 池化操作（没有权重的函数不能称为层）\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12*4*4)       # 必须手动flatten\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        # t = F.softmax(t, dim=1)           # 不直接在forward中用softmax，而是在训练过程中用cross-entropy损失函数计算loss，其中自带softmax\n",
    "        \n",
    "        return t\n",
    "    \n",
    "    \n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a37b7f",
   "metadata": {},
   "source": [
    "## Starting out with TensorBoard (Network Graph and Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "767cad5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T10:02:53.484464Z",
     "start_time": "2023-10-13T10:02:53.032857Z"
    }
   },
   "outputs": [],
   "source": [
    "tb = SummaryWriter()\n",
    "\n",
    "network = Network()\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb.add_image(\"image\", grid)         # 添加图像\n",
    "tb.add_graph(network, images)       # 添加网络和图像张量\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eb2519e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T10:43:27.928197Z",
     "start_time": "2023-10-13T10:40:18.268467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 47184 loss: 336.92509910464287\n",
      "epoch 1 total_correct: 51538 loss: 230.06804628670216\n",
      "epoch 2 total_correct: 52374 loss: 206.95529808104038\n",
      "epoch 3 total_correct: 52672 loss: 198.8001050800085\n",
      "epoch 4 total_correct: 52965 loss: 190.70277906954288\n",
      "epoch 5 total_correct: 53239 loss: 184.03623577952385\n",
      "epoch 6 total_correct: 53300 loss: 180.3358246088028\n",
      "epoch 7 total_correct: 53453 loss: 178.6155837327242\n",
      "epoch 8 total_correct: 53520 loss: 176.7629645317793\n",
      "epoch 9 total_correct: 53662 loss: 173.8362509161234\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)   # 优化器使用Adam\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb = SummaryWriter()\n",
    "tb.add_image(\"image\", grid)         # 添加图像\n",
    "tb.add_graph(network, images)       # 添加网络和图像张量\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for batch in train_loader:  # get batch \n",
    "        images, labels = batch\n",
    "\n",
    "        preds = network(images)  # pass batch\n",
    "        loss = F.cross_entropy(preds, labels)  # calculate loss\n",
    "\n",
    "        optimizer.zero_grad()    # 计算梯度之前要确保当前没有梯度值（PyTorch会自动累加计算过的梯度）\n",
    "        loss.backward()     # calculate gradients\n",
    "        optimizer.step()    # update weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)              # scalar标量，即添加一个数字\n",
    "    tb.add_scalar(\"Number Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct / len(train_set), epoch)\n",
    "    \n",
    "    tb.add_histogram(\"conv1.bias\", network.conv1.bias, epoch)  # 添加直方图\n",
    "    tb.add_histogram(\"conv1.weight\", network.conv1.weight, epoch)\n",
    "    tb.add_histogram(\"conv1.weight.grad\", network.conv1.weight.grad, epoch)\n",
    "    \n",
    "    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "    \n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fbccba4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T10:52:59.272348Z",
     "start_time": "2023-10-13T10:52:47.728521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 46521 loss: 353.7856948375702\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)   # 优化器使用Adam\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb = SummaryWriter()\n",
    "tb.add_image(\"image\", grid)         # 添加图像\n",
    "tb.add_graph(network, images)       # 添加网络和图像张量\n",
    "\n",
    "for epoch in range(1):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for batch in train_loader:  # get batch \n",
    "        images, labels = batch\n",
    "\n",
    "        preds = network(images)  # pass batch\n",
    "        loss = F.cross_entropy(preds, labels)  # calculate loss\n",
    "\n",
    "        optimizer.zero_grad()    # 计算梯度之前要确保当前没有梯度值（PyTorch会自动累加计算过的梯度）\n",
    "        loss.backward()     # calculate gradients\n",
    "        optimizer.step()    # update weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)              # scalar标量，即添加一个数字\n",
    "    tb.add_scalar(\"Number Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct / len(train_set), epoch)\n",
    "    \n",
    "#     tb.add_histogram(\"conv1.bias\", network.conv1.bias, epoch)  # 添加直方图\n",
    "#     tb.add_histogram(\"conv1.weight\", network.conv1.weight, epoch)\n",
    "#     tb.add_histogram(\"conv1.weight.grad\", network.conv1.weight.grad, epoch)\n",
    "\n",
    "    for name, weight in network.named_parameters():        # 将每层的权重和梯度全部画进直方图\n",
    "        tb.add_histogram(name, weight, epoch)\n",
    "        tb.add_histogram(f\"{name}.grad\", weight.grad, epoch)\n",
    "    \n",
    "    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "    \n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2604e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T10:54:55.173375Z",
     "start_time": "2023-10-13T10:54:55.162522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5])\n",
      "conv1.bias torch.Size([6])\n",
      "conv2.weight torch.Size([12, 6, 5, 5])\n",
      "conv2.bias torch.Size([12])\n",
      "fc1.weight torch.Size([120, 192])\n",
      "fc1.bias torch.Size([120])\n",
      "fc2.weight torch.Size([60, 120])\n",
      "fc2.bias torch.Size([60])\n",
      "out.weight torch.Size([10, 60])\n",
      "out.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, weight in network.named_parameters():\n",
    "    print(name, weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3dbbea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T10:55:47.508133Z",
     "start_time": "2023-10-13T10:55:47.489579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight.grad torch.Size([6, 1, 5, 5])\n",
      "conv1.bias.grad torch.Size([6])\n",
      "conv2.weight.grad torch.Size([12, 6, 5, 5])\n",
      "conv2.bias.grad torch.Size([12])\n",
      "fc1.weight.grad torch.Size([120, 192])\n",
      "fc1.bias.grad torch.Size([120])\n",
      "fc2.weight.grad torch.Size([60, 120])\n",
      "fc2.bias.grad torch.Size([60])\n",
      "out.weight.grad torch.Size([10, 60])\n",
      "out.bias.grad torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, weight in network.named_parameters():\n",
    "    print(f\"{name}.grad\", weight.grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0927462",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69da5085",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:06:15.754588Z",
     "start_time": "2023-10-13T11:06:15.742138Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9315660f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:07:11.701379Z",
     "start_time": "2023-10-13T11:07:11.687428Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = dict(                # 先用字典存放\n",
    "    lr = [0.01, 0.001],\n",
    "    batch_size = [10, 100, 1000],\n",
    "    shuffle = [True, False]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dfeab68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:08:08.459060Z",
     "start_time": "2023-10-13T11:08:08.438814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.01, 0.001], [10, 100, 1000], [True, False]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_values = [v for v in parameters.values()]  # 再转换成列表\n",
    "param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "423ba602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:11:00.560404Z",
     "start_time": "2023-10-13T11:11:00.552282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 10 True\n",
      "0.01 10 False\n",
      "0.01 100 True\n",
      "0.01 100 False\n",
      "0.01 1000 True\n",
      "0.01 1000 False\n",
      "0.001 10 True\n",
      "0.001 10 False\n",
      "0.001 100 True\n",
      "0.001 100 False\n",
      "0.001 1000 True\n",
      "0.001 1000 False\n"
     ]
    }
   ],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values):  # 取得列表元素的所有组合\n",
    "    print(lr, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3784fb73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:48:27.745461Z",
     "start_time": "2023-10-13T11:23:27.273553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 45495 loss: 38554.31323544588\n",
      "epoch 1 total_correct: 48130 loss: 32533.88545371301\n",
      "epoch 2 total_correct: 48428 loss: 32515.408893563435\n",
      "epoch 3 total_correct: 48587 loss: 32911.61459766561\n",
      "epoch 4 total_correct: 48615 loss: 32486.069676255574\n",
      "epoch 0 total_correct: 46429 loss: 36786.75653106999\n",
      "epoch 1 total_correct: 48587 loss: 32004.350982231117\n",
      "epoch 2 total_correct: 48838 loss: 31077.62347409269\n",
      "epoch 3 total_correct: 48821 loss: 31543.936647808878\n",
      "epoch 4 total_correct: 49104 loss: 31230.010721804574\n",
      "epoch 0 total_correct: 45676 loss: 37385.97422838211\n",
      "epoch 1 total_correct: 50726 loss: 25126.520177721977\n",
      "epoch 2 total_correct: 51479 loss: 23055.81790059805\n",
      "epoch 3 total_correct: 51792 loss: 22320.764541625977\n",
      "epoch 4 total_correct: 52071 loss: 21543.058294057846\n",
      "epoch 0 total_correct: 47617 loss: 33181.12445324659\n",
      "epoch 1 total_correct: 51632 loss: 22732.87554383278\n",
      "epoch 2 total_correct: 52338 loss: 20794.487385451794\n",
      "epoch 3 total_correct: 52644 loss: 20121.633495390415\n",
      "epoch 4 total_correct: 52913 loss: 19087.266770005226\n",
      "epoch 0 total_correct: 37060 loss: 59773.004710674286\n",
      "epoch 1 total_correct: 46427 loss: 34598.08140993118\n",
      "epoch 2 total_correct: 49191 loss: 28733.218908309937\n",
      "epoch 3 total_correct: 50630 loss: 25321.993470191956\n",
      "epoch 4 total_correct: 51487 loss: 23082.856088876724\n",
      "epoch 0 total_correct: 38577 loss: 55659.19607877731\n",
      "epoch 1 total_correct: 49099 loss: 28788.268625736237\n",
      "epoch 2 total_correct: 51346 loss: 23674.606829881668\n",
      "epoch 3 total_correct: 51970 loss: 21758.935809135437\n",
      "epoch 4 total_correct: 52548 loss: 20045.947074890137\n",
      "epoch 0 total_correct: 47273 loss: 33658.420148799196\n",
      "epoch 1 total_correct: 51547 loss: 22853.078981419094\n",
      "epoch 2 total_correct: 52688 loss: 19708.220724349376\n",
      "epoch 3 total_correct: 53311 loss: 17853.179579495918\n",
      "epoch 4 total_correct: 53741 loss: 16610.334794864175\n",
      "epoch 0 total_correct: 46999 loss: 34615.12038012035\n",
      "epoch 1 total_correct: 51380 loss: 23372.32344626682\n",
      "epoch 2 total_correct: 52427 loss: 20494.75044914987\n",
      "epoch 3 total_correct: 52970 loss: 18823.21369794896\n",
      "epoch 4 total_correct: 53373 loss: 17640.70098273398\n",
      "epoch 0 total_correct: 42693 loss: 46373.80664348602\n",
      "epoch 1 total_correct: 48878 loss: 29901.576352119446\n",
      "epoch 2 total_correct: 50704 loss: 25596.920336782932\n",
      "epoch 3 total_correct: 51724 loss: 22843.967719376087\n",
      "epoch 4 total_correct: 52348 loss: 20939.551135897636\n",
      "epoch 0 total_correct: 42686 loss: 46046.639370918274\n",
      "epoch 1 total_correct: 49031 loss: 29443.647602200508\n",
      "epoch 2 total_correct: 51001 loss: 24793.2614967227\n",
      "epoch 3 total_correct: 51993 loss: 22154.922692477703\n",
      "epoch 4 total_correct: 52566 loss: 20513.745637238026\n",
      "epoch 0 total_correct: 29298 loss: 90328.03231477737\n",
      "epoch 1 total_correct: 42242 loss: 46992.692828178406\n",
      "epoch 2 total_correct: 44145 loss: 40977.49638557434\n",
      "epoch 3 total_correct: 45436 loss: 37709.032356739044\n",
      "epoch 4 total_correct: 46400 loss: 35345.35074234009\n",
      "epoch 0 total_correct: 25782 loss: 100454.64146137238\n",
      "epoch 1 total_correct: 42486 loss: 45175.95058679581\n",
      "epoch 2 total_correct: 45021 loss: 38084.320068359375\n",
      "epoch 3 total_correct: 46163 loss: 34915.78960418701\n",
      "epoch 4 total_correct: 47211 loss: 32791.26733541489\n"
     ]
    }
   ],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values):\n",
    "    comment = f\"batch_size={batch_size} lr={lr} shuffle={shuffle}\"\n",
    "    \n",
    "    # training process\n",
    "    network = Network()\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "    \n",
    "    images, labels = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    \n",
    "    tb = SummaryWriter(comment=comment)  # Summary会将comment参数的内容设置为本次运行的名称，从而可以用参数值来表示每次运行\n",
    "    tb.add_image(\"image\", grid)         # 添加图像\n",
    "    tb.add_graph(network, images)       # 添加网络和图像张量\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        for batch in train_loader:  # get batch \n",
    "            images, labels = batch\n",
    "            preds = network(images)  # pass batch\n",
    "            loss = F.cross_entropy(preds, labels)  # calculate loss\n",
    "            optimizer.zero_grad()    # 计算梯度之前要确保当前没有梯度值（PyTorch会自动累加计算过的梯度）\n",
    "            loss.backward()     # calculate gradients\n",
    "            optimizer.step()    # update weights\n",
    "\n",
    "            total_loss += loss.item() * batch_size      # loss太小，乘batch_size方便比较大小\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        tb.add_scalar(\"Loss\", total_loss, epoch)              # scalar标量，即添加一个数字\n",
    "        tb.add_scalar(\"Number Correct\", total_correct, epoch)\n",
    "        tb.add_scalar(\"Accuracy\", total_correct / len(train_set), epoch)\n",
    "\n",
    "    #     tb.add_histogram(\"conv1.bias\", network.conv1.bias, epoch)  # 添加直方图\n",
    "    #     tb.add_histogram(\"conv1.weight\", network.conv1.weight, epoch)\n",
    "    #     tb.add_histogram(\"conv1.weight.grad\", network.conv1.weight.grad, epoch)\n",
    "\n",
    "        for name, weight in network.named_parameters():        # 将每层的权重和梯度全部画进直方图\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "            tb.add_histogram(f\"{name}.grad\", weight.grad, epoch)\n",
    "\n",
    "        print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "\n",
    "tb.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e9fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
